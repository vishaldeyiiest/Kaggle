{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "ba5d298e-30c9-45df-b980-494bd5d4648d",
        "_uuid": "652ea1e53234b268c43a1b9a7352963315ff938c"
      },
      "cell_type": "markdown",
      "source": "Credits:\n1. [Keras - Bidirectional LSTM baseline ( lb 0.051)](https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-051/code)"
    },
    {
      "metadata": {
        "_cell_guid": "1344ecaf-6fc2-4156-90c7-3d6390c98244",
        "_uuid": "77e190d5fdeb764ddc8aaf4d452b6b178ecb7743",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Embedding, Input\nfrom keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bfccdb63-b532-4cc0-b42d-7f0e21d00975",
        "_uuid": "51c84d4d71fda591dc0bcfa2f749f9c706fc1ef7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fdffb666-73d9-47f7-b1e0-b92e073c165c",
        "_uuid": "6b9b749391916d5bd565dd2ac1c9a12d2bbdaac1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_X = train[\"comment_text\"].fillna(\"XX\").values\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ntrain_Y = train[list_classes].values\ntest_X = test[\"comment_text\"].fillna(\"XX\").values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bf740f2f-716c-480e-8271-3eca1370d48b",
        "_uuid": "1fb37d747fc06e1209b055e5a49038a77acd67aa",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "maxlen = 120\nmax_features = 2000\ntoken = text.Tokenizer(num_words=max_features)\ntoken.fit_on_texts(list(train_X))\ntrain_X = token.texts_to_sequences(train_X)\ntest_X = token.texts_to_sequences(test_X) \ntrain_X = sequence.pad_sequences(train_X, maxlen=maxlen)\ntest_X = sequence.pad_sequences(test_X, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a855d061-b803-4a9e-8526-4dba3ac3e24d",
        "_uuid": "0003ee0d03b2c64b35b841bac350fb4014768d08",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_model():\n    embed_size = 128\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size)(inp)\n    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n    x = GlobalMaxPool1D()(x)\n    x = Dropout(0.1)(x)\n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a2268b90-a00b-4d66-9ea1-34e675a9fd4e",
        "_uuid": "bcb78c4132ac7a5f65780c5273dbb59053d249ae",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = get_model()\nbatch_size = 32\nepochs = 3\nfile_path=\"weights_base.best.hdf5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n\ncallbacks_list = [checkpoint, early] #early\nmodel.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "39ee4415-7d53-4c6b-a284-60c75ec60018",
        "_uuid": "c85c151d6acedea0adc736738eb019efdeb8a1d3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.load_weights(file_path)\npreds = model.predict(test_X)\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nsample_submission[list_classes] = preds\n\nsample_submission.to_csv(\"starter_lstm.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.6.3",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
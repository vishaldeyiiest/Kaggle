{
  "cells": [
    {
      "metadata": {
        "_uuid": "8c258d8b7520fbeb8a9a2baf8416704fe1109078",
        "_cell_guid": "0261b396-1ecd-4019-ba5c-284fb06f892c"
      },
      "cell_type": "markdown",
      "source": "Credits:\n1. [Keras - Bidirectional LSTM baseline ( lb 0.051)](https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-051/code)"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "77e190d5fdeb764ddc8aaf4d452b6b178ecb7743",
        "_cell_guid": "1344ecaf-6fc2-4156-90c7-3d6390c98244",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom string import punctuation\n\nfrom gensim.models import KeyedVectors\nfrom keras.models import Model\nfrom keras.layers import Dense, Embedding, Input\nfrom keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\nfrom keras.preprocessing import text, sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "51c84d4d71fda591dc0bcfa2f749f9c706fc1ef7",
        "_cell_guid": "bfccdb63-b532-4cc0-b42d-7f0e21d00975",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "ba2f74ad368e5f101555e2ad875e631712e2060b",
        "_cell_guid": "04bd3afa-ed0d-4e6b-a1a1-17231394c627",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train['comment_text'] = train['comment_text'].apply(str)\ntest['comment_text'] = test['comment_text'].apply(str)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "6b9b749391916d5bd565dd2ac1c9a12d2bbdaac1",
        "_cell_guid": "fdffb666-73d9-47f7-b1e0-b92e073c165c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_X = train[\"comment_text\"].fillna(\"XX\").values\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ntrain_Y = train[list_classes].values\ntest_X = test[\"comment_text\"].fillna(\"XX\").values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "13e9b26987d80945471d37af0c1429892a2a3f06",
        "_cell_guid": "4d03d339-7264-4ef9-99c7-906df692caab",
        "trusted": false
      },
      "cell_type": "code",
      "source": "special_character_removal=re.compile(r'[^a-z\\d ]',re.IGNORECASE)\n#regex to replace all numerics\nreplace_numbers=re.compile(r'\\d+',re.IGNORECASE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "9a10424ba5fae4124a571af7639eaf48e015c8dc",
        "_cell_guid": "db0efb11-b022-47a8-a384-178a7250e182",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n    # Convert words to lower case and split them\n    text = text.lower().split()\n    # Optionally, remove stop words\n    if remove_stopwords:\n        stops = set(stopwords.words(\"english\"))\n        text = [w for w in text if not w in stops]\n        \n    text = \" \".join(text)\n    #Remove Special Characters\n    text=special_character_removal.sub('',text)\n    #Replace Numbers\n    text=replace_numbers.sub('n',text)\n\n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    # Return a list of words\n    return(text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "0226082b8c01ee1137552f9f20be7d039f053ef3",
        "_cell_guid": "ebe3fc01-1cc9-409f-95b9-a4e520800542",
        "trusted": false
      },
      "cell_type": "code",
      "source": "comments = []\nfor text in train_X:\n    comments.append(text_to_wordlist(text))\n    \ntest_comments=[]\nfor text in test_X:\n    test_comments.append(text_to_wordlist(text))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "125fe561788f59f585774eba71a3aedf5af95669",
        "_cell_guid": "31b8f90a-88d3-439d-a0ae-5e5b8ac3c472",
        "trusted": false
      },
      "cell_type": "code",
      "source": "maxlen = 120\nmax_features = 10000\ntoken = Tokenizer(num_words=max_features)\ntoken.fit_on_texts(comments + test_comments)\ntrain_seq = token.texts_to_sequences(train_X)\ntest_seq = token.texts_to_sequences(test_X) \ntrain_X = sequence.pad_sequences(train_seq, maxlen=maxlen)\ntest_X = sequence.pad_sequences(test_seq, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "43efcde55c6f4b273d5916723f062d7e64a66f40",
        "_cell_guid": "e03a4486-025f-46e3-823e-dfd7cca34514",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_model():\n    embed_size = 100\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size)(inp)\n    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n    x = GlobalMaxPool1D()(x)\n    x = Dropout(0.1)(x)\n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "59540f6a2a597ef17fac93fd14f904a68635e78c",
        "_cell_guid": "216f29ef-89a3-423f-8aa7-36c0cec036d8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "model = get_model()\nbatch_size = 32\nepochs = 3\nfile_path=\"weights_base.best.hdf5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n\ncallbacks_list = [checkpoint, early] #early\nmodel.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "124216c46a861007d670474cab65386b8ce511fd",
        "_cell_guid": "808bbf80-c0da-475f-82bc-c76b34e377f2",
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.load_weights(file_path)\npreds = model.predict(test_X)\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nsample_submission[list_classes] = preds\n\nsample_submission.to_csv(\"starter_lstm.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
{
  "cells": [
    {
      "metadata": {
        "_uuid": "c607cddb94d6568cc7047bc6eed145c8f0871ab4",
        "_cell_guid": "4fe2cfa7-be44-441c-a2b2-aa682990e93b"
      },
      "cell_type": "markdown",
      "source": "# USING STACKING of BASE models\n## Thank you Kagglers for their informative notebooks:\nHonorable Mentions:\n1. [Stacked Regressions : Top 4% on LeaderBoard](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard/output) by Serigne.\n2. [Comprehensive data exploration with Python](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) by Pedro Marcelino.\n3. [Regularized Linear Models](https://www.kaggle.com/apapiu/regularized-linear-models) by Alexandru Papiu.\n\n"
    },
    {
      "metadata": {
        "_uuid": "0ead21431254e637faa2b5f9a2a7318345408692",
        "_cell_guid": "cbe88d66-9413-42e3-a52b-fd305bfcf6be",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom matplotlib import pyplot as plt\nimport warnings\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\nwarnings.filterwarnings('ignore')\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1687ca8085647ef41a49e5cdff1a2776b391f824",
        "_cell_guid": "933c879d-334f-4333-a8d4-716c218bcd16",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "adf1e0110cadf937b25e1b2e83679a55c08361ec",
        "_cell_guid": "fc45386a-2619-45bb-9d31-d8bb313024b8"
      },
      "cell_type": "markdown",
      "source": "## Data Preprocessing "
    },
    {
      "metadata": {
        "_uuid": "eb66ec16e7966d2733c25218dcaa1ce24a67a1c1",
        "_cell_guid": "0ec6d432-7e59-49cf-b62f-ab242d4b272d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice')\nplt.xlabel('GrLivArea')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4202d65f334adc02efcc126f8a36faeab921da24",
        "_cell_guid": "26a830ab-8c22-41f2-b187-c11504d2c6ca"
      },
      "cell_type": "markdown",
      "source": "### Remove outliers"
    },
    {
      "metadata": {
        "_cell_guid": "c3c1e106-f68a-4253-9777-adf3e0bd4fc3",
        "_uuid": "5f470542c120b316424b6c79fac8ecc77365155a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = train.drop(train[(train['GrLivArea']>4200) & (train['SalePrice']<300000)].index)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1432f590f6a766bf67c3476e0bdf683ab4c7f85b",
        "_cell_guid": "90e5e004-9da5-4183-8020-ef7b3625e791",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#Check the new distribution \nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7ced5576760a26e46c9127e3d50a6a64e52cbaf7",
        "_cell_guid": "f8d3186b-d958-46c8-a7bc-4e756f699341",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "all_data = pd.concat((train, test))\nall_data = all_data.drop(['SalePrice'], axis = 1)\nall_data.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d780f65e-2c33-40bf-aa20-9425ffe58682",
        "_uuid": "bddf35699ae79ff9f49e4104b0f694bb98c02e49",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n#log transform skewed numeric features:\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "406674b02a9efebce329e698ca2462e459e576d7",
        "_cell_guid": "df57cbfb-8ab5-423f-a7cc-41cb14c14cc9"
      },
      "cell_type": "markdown",
      "source": "### Filling NA values"
    },
    {
      "metadata": {
        "_uuid": "26990e066cf023954ff866cf4d37328c9e1c5a57",
        "_cell_guid": "c3ad89a5-d914-41ee-b35b-1d5873e54717",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nf, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd106f3d7f5fee5dda57683284acccbc5f6be3e4",
        "_cell_guid": "bb5e8f9f-3775-42d8-b3d4-6bd2bf10614c"
      },
      "cell_type": "markdown",
      "source": "### Correlation of Feaures"
    },
    {
      "metadata": {
        "_uuid": "fc19a8a33e056c57891b073771cd71d5528a00c7",
        "_cell_guid": "1d70ba54-2bbb-47ab-9367-3e68e98e5e76",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def plot_correlation_map():\n    corr = train.corr()\n    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(corr, square = True)\n\nplot_correlation_map()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f99d8ba93425ca4da223ae53ab2e7baaa5e33bbf",
        "_cell_guid": "e4e73452-9703-437d-a2ba-9cbc511e54a2",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#all_data = all_data.fillna(all_data.mean())\nall_data.info()\nall_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n\n#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\n\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n\nall_data = all_data.drop(['Utilities'], axis = 1)\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n\n\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\nall_data.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1193a7a8-34b6-4a46-a36a-fa04c2a227ad",
        "_uuid": "e859d90ac712967b2f213143045a5f2f1d82e024",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "all_data.shape\n# Adding total sqfootage feature \nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "df8306c9-0ffd-4b3f-b23e-a83241228e65",
        "_uuid": "015fe2f63ea23415af741f2111e6b4f1e02d1680",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6c5c123f6cf5082986f44b6a8b668e2f781af62d",
        "_cell_guid": "c5d09dfc-8fb9-440a-8ae6-96cd1c6a6944",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "616a3be0280c285406977fb72abd1d546883c4a1",
        "_cell_guid": "f52f686a-bea1-4669-8505-ca736c091846",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "all_data = pd.get_dummies(all_data)\nall_data.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c99ccba0-c417-4041-bc13-7e55eb73b7b4",
        "_uuid": "3a09d3ea21df0ee95356e8465127b6226358b60e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_X = all_data[:len(train)]\ntest = all_data[len(train):]\ntrain_Id, test_Id = train_X['Id'], test['Id']\ntrain_X.drop(['Id'], axis = 1, inplace = True)\ntest.drop(['Id'], axis = 1, inplace = True)\n#train_X = pd.DataFrame(train_X)\ntrain_Y = train['SalePrice']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5c0dc8a27ad9ac5e7c999183b1de341a4a0c33cc",
        "_cell_guid": "75ed86aa-a8e4-468c-a96b-6ecad0b23643"
      },
      "cell_type": "markdown",
      "source": "## STACKING BASE MODELS: Kernel Ridge Regression, Lasso, Elastic Net, Gradient Boosting"
    },
    {
      "metadata": {
        "_cell_guid": "7f2ab843-2e0c-4f8c-a82a-6185809c6cc0",
        "_uuid": "73d6cf7ed06818caab443056ea0c71780f82c388",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, \n                                   max_features='sqrt', loss='huber', random_state =5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d46b2def-52a7-421d-9158-281fd707d11d",
        "_uuid": "12d859dafa03f673c4dd0160b20d9c99b0e9e92a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model_lgb = lgb.LGBMRegressor(objective='regression', learning_rate=0.05, n_estimators=500,\n                              max_bin = 55, bagging_fraction = 0.8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fa71e6347a4c3bf01b278fc10774d50e79491477",
        "_cell_guid": "26a9fb58-0ea5-41ef-bdd9-9c85b58af40d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import xgboost as xgb\nmodel_xgb = xgb.XGBRegressor(n_estimators=2000, max_depth=3, learning_rate=0.05) #the params were tuned using xgb.cv\nmodel_xgb.fit(train_X, train_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2641bf48-e5da-480d-9d4b-36f70584cb3b",
        "_uuid": "f2a17f83bc483277b2a56f16e546a21287a4be08",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    #kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    rmse= np.sqrt(-cross_val_score(model, train_X.values, train_Y.values, scoring=\"neg_mean_squared_error\"))\n    return(rmse)\n\ndef rmsle_cv_(model):\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    rmse= np.sqrt(-cross_val_score(model, train_X.values, train_Y, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b766a6c7-6a0a-4df9-ad5a-ed199b6be24a",
        "_uuid": "e7a325389d0693abec5815cbf0712da1326f7702",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "score = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n''''\nscore = rmsle_cv_(lasso)\nprint(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv_(ENet)\nprint(\"ENet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv_(KRR)\nprint(\"KRR score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv_(GBoost)\nprint(\"Gboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv_(model_lgb)\nprint(\"Light GBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d19eade1-3495-4fec-8b6d-6abadb21bc4f",
        "_uuid": "59aacb2951eeb7733996c693f98b653e87685bcb",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6f412a4b-e410-4bde-8ef7-392c0935c8f4",
        "_uuid": "085352ff97c486e98eb3dbf663f06df006fb4b89",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n                                                 meta_model = lasso)\n\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "95e9a1ed-2f09-4983-b21b-5030f3a16bda",
        "_uuid": "252a1ff0eaf4dcadd79d883ee8aa2d2b520e67c2",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_squared_error\nxgb_train_pred = model_xgb.predict(train_X)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(\"XGB model score: {:.4f} \".format(np.sqrt(mean_squared_error(train_Y, xgb_train_pred))))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5cfa5202-4a69-4e35-b775-c66409ab53ac",
        "_uuid": "08b6ce704da2bbe3b852d12f8a71842baac654aa",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model_lgb.fit(train_X, train_Y)\nlgb_train_pred = model_lgb.predict(train_X)\nlgb_pred = np.expm1(model_lgb.predict(test))\nprint(\"LGB model score: {:.4f} \".format(np.sqrt(mean_squared_error(train_Y, lgb_train_pred))))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "953378ef-2b97-40ab-8e5b-e2aa966d3364",
        "_uuid": "960c242c9971e68ca034f1dab7cccb5c346af1b3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "stacked_averaged_models.fit(train_X.values, train_Y.values)\nstacked_train_pred = stacked_averaged_models.predict(train_X.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\nprint(\"Stacked average models score: {:.4f} \".format(np.sqrt(mean_squared_error(train_Y, stacked_train_pred))))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ebe0c3c0-fe9a-4da4-ae67-631771054c08",
        "_uuid": "951377cad7812b2df8f5354cb4f17203ff83d731",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "solution = pd.DataFrame()\nsolution['id'] = test_Id\nsolution['SalePrice'] = xgb_pred*0.2 + lgb_pred*0.2 + stacked_pred*0.6\nsolution.to_csv(\"submission_xgb.csv\", index = False)\nsolution.head()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "version": "3.6.3",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}